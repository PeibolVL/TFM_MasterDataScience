{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este fichero se realizara la obtención de los datos de concentraciones de contaminantes atmosféricos proporcionados por la estaciones de medición del ayuntamiento de Madrid."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "from zipfile import ZipFile\n",
    "import fileinput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamiento de los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se establece la fuente principal del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "fuente_principal=!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enlace de la web de datos de calidad del aire horario del ayuntamiento de madrid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "enlace = \"https://datos.madrid.es/portal/site/egob/menuitem.c05c1f754a33a9fbe4b2e4b284f1a5a0/?vgnextoid=f3c0f7d512273410VgnVCM2000000c205a0aRCRD&vgnextchannel=374512b9ace9f310VgnVCM100000171f5a0aRCRD&vgnextfmt=default\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se realiza una llamada a la página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = urllib.request.urlopen(enlace)\n",
    "CalidadAire=BeautifulSoup(url.read(),'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se genera un diccionario vacío, donde se albergará los años como llave y en los enlaces de descarga como valares. Se tendrá que especificar los años que se quieran estudiar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_link={}\n",
    "ano_inicio=2015\n",
    "ano_fin=2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se busca la etiqueta en la que está alojada la información de los datos de calidad del aire horario, y se extrae el año y el enlace de descarga de los ficheros, para guardarlo en el diccionario antes creado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "links=CalidadAire.find_all(\"a\", class_=\"asociada-link ico-zip\")\n",
    "for line in links:\n",
    "    link='https://datos.madrid.es'+line.get('href')\n",
    "    ano=int(line.find_previous(\"p\", class_=\"info-title\").string)\n",
    "    if (ano >= ano_inicio) & (ano <= ano_fin):\n",
    "        dict_link[ano]=link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al tener ya un diccionario con los años y los enlaces de descarga de datos horarios para cada año, se procederá a realizar la descarga de los datos para los años especificados anteriormente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pero antes de todo se crea la carpeta \"data\" y una subcarpeta \"source\" donde se almacenará toda la información descargada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "el directorio ya existe\n"
     ]
    }
   ],
   "source": [
    "fuente_datos='./data/source'\n",
    "\n",
    "if os.path.isdir(fuente_datos):\n",
    "    print('el directorio ya existe')\n",
    "else:\n",
    "    os.makedirs(fuente_datos)\n",
    "    print('Se han creado el directorio')\n",
    "\n",
    "os.chdir(fuente_datos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se comienza con la descarga de los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando la información del año 2019...\n",
      "¡Año 2019 completado!\n",
      "Descargando la información del año 2018...\n",
      "¡Año 2018 completado!\n",
      "Descargando la información del año 2017...\n",
      "¡Año 2017 completado!\n",
      "Descargando la información del año 2016...\n",
      "¡Año 2016 completado!\n",
      "Descargando la información del año 2015...\n",
      "¡Año 2015 completado!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for key,value in dict_link.items():\n",
    "        print(\"Descargando la información del año %s...\"%format(key))\n",
    "        zipname=str(key)+\".zip\"\n",
    "        urllib.request.urlretrieve(value, zipname)\n",
    "        with ZipFile(zipname, 'r') as zipObj:\n",
    "            # Coge una lista de todos archivo del fichero ZIP\n",
    "            listOfFileNames = zipObj.namelist()\n",
    "            # Itera sobre los nombre de los ficheros\n",
    "            for fileName in listOfFileNames:\n",
    "                # Comprueba que tiene una terminación .txt\n",
    "                if fileName.endswith('.txt'): \n",
    "                    # Extrae el archivo\n",
    "                    zipObj.extract(fileName, './')\n",
    "        \n",
    "        print(\"¡Año %s completado!\"%format(key))\n",
    "\n",
    "os.remove('.DS_Store')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cambio de nombre de los ficheros que albergan los datos de contaminación del aire, para que todos tengan la estructura yymm.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes={\"ene_mo\":\"01\",\"ene\":\"01\",\n",
    "    \"feb_mo\":\"02\",\"feb\":\"02\",\n",
    "    \"mar_mo\":\"03\",\"mar\":\"03\",\n",
    "    \"abr_mo\":\"04\",\"abr\":\"04\",\n",
    "    \"may_mo\":\"05\",\"may\":\"05\",\n",
    "    \"jun_mo\":\"06\",\"jun\":\"06\",\n",
    "    \"jul_mo\":\"07\",\"jul\":\"07\",\n",
    "    \"ago_mo\":\"08\",\"ago\":\"08\",\n",
    "    \"sep_mo\":\"09\",\"sep\":\"09\",\n",
    "    \"oct_mo\":\"10\",\"oct\":\"10\",\n",
    "    \"nov_mo\":\"11\",\"nov\":\"11\",\n",
    "    \"dic_mo\":\"12\",\"dic\":\"12\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501.txt\n",
      "['1501']\n",
      "1502.txt\n",
      "['1502']\n",
      "1503.txt\n",
      "['1503']\n",
      "1504.txt\n",
      "['1504']\n",
      "1505.txt\n",
      "['1505']\n",
      "1506.txt\n",
      "['1506']\n",
      "1507.txt\n",
      "['1507']\n",
      "1508.txt\n",
      "['1508']\n",
      "1509.txt\n",
      "['1509']\n",
      "1510.txt\n",
      "['1510']\n",
      "1511.txt\n",
      "['1511']\n",
      "1512.txt\n",
      "['1512']\n",
      "1601.txt\n",
      "['1601']\n",
      "1602.txt\n",
      "['1602']\n",
      "1603.txt\n",
      "['1603']\n",
      "1604.txt\n",
      "['1604']\n",
      "1605.txt\n",
      "['1605']\n",
      "1606.txt\n",
      "['1606']\n",
      "1607.txt\n",
      "['1607']\n",
      "1608.txt\n",
      "['1608']\n",
      "1609.txt\n",
      "['1609']\n",
      "1610.txt\n",
      "['1610']\n",
      "1611.txt\n",
      "['1611']\n",
      "1612.txt\n",
      "['1612']\n",
      "1701.txt\n",
      "['1701']\n",
      "1702.txt\n",
      "['1702']\n",
      "1703.txt\n",
      "['1703']\n",
      "1704.txt\n",
      "['1704']\n",
      "1705.txt\n",
      "['1705']\n",
      "1706.txt\n",
      "['1706']\n",
      "1707.txt\n",
      "['1707']\n",
      "1708.txt\n",
      "['1708']\n",
      "1709.txt\n",
      "['1709']\n",
      "1710.txt\n",
      "['1710']\n",
      "1711.txt\n",
      "['1711']\n",
      "1712.txt\n",
      "['1712']\n",
      "1801.txt\n",
      "['1801']\n",
      "1802.txt\n",
      "['1802']\n",
      "1803.txt\n",
      "['1803']\n",
      "1804.txt\n",
      "['1804']\n",
      "1805.txt\n",
      "['1805']\n",
      "1806.txt\n",
      "['1806']\n",
      "1807.txt\n",
      "['1807']\n",
      "1808.txt\n",
      "['1808']\n",
      "1809.txt\n",
      "['1809']\n",
      "1810.txt\n",
      "['1810']\n",
      "1811.txt\n",
      "['1811']\n",
      "1812.txt\n",
      "['1812']\n",
      "1901.txt\n",
      "['1901']\n",
      "1902.txt\n",
      "['1902']\n",
      "1903.txt\n",
      "['1903']\n",
      "2015.zip\n",
      "['2015']\n",
      "2016.zip\n",
      "['2016']\n",
      "2017.zip\n",
      "['2017']\n",
      "2018.zip\n",
      "['2018']\n",
      "2019.zip\n",
      "['2019']\n",
      "abr17.txt\n",
      "['17']\n",
      "abr_mo15.txt\n",
      "['15']\n",
      "abr_mo16.txt\n",
      "['16']\n",
      "abr_mo18.txt\n",
      "['18']\n",
      "abr_mo19.txt\n",
      "['19']\n",
      "ago17.txt\n",
      "['17']\n",
      "ago_mo15.txt\n",
      "['15']\n",
      "ago_mo16.txt\n",
      "['16']\n",
      "ago_mo18.txt\n",
      "['18']\n",
      "dic17.txt\n",
      "['17']\n",
      "dic_mo15.txt\n",
      "['15']\n",
      "dic_mo16.txt\n",
      "['16']\n",
      "dic_mo18.txt\n",
      "['18']\n",
      "ene17.txt\n",
      "['17']\n",
      "ene_mo15.txt\n",
      "['15']\n",
      "ene_mo16.txt\n",
      "['16']\n",
      "ene_mo18.txt\n",
      "['18']\n",
      "ene_mo19.txt\n",
      "['19']\n",
      "feb17.txt\n",
      "['17']\n",
      "feb_mo15.txt\n",
      "['15']\n",
      "feb_mo16.txt\n",
      "['16']\n",
      "feb_mo18.txt\n",
      "['18']\n",
      "feb_mo19.txt\n",
      "['19']\n",
      "jul17.txt\n",
      "['17']\n",
      "jul_mo15.txt\n",
      "['15']\n",
      "jul_mo16.txt\n",
      "['16']\n",
      "jul_mo18.txt\n",
      "['18']\n",
      "jun17.txt\n",
      "['17']\n",
      "jun_mo15.txt\n",
      "['15']\n",
      "jun_mo16.txt\n",
      "['16']\n",
      "jun_mo18.txt\n",
      "['18']\n",
      "mar17.txt\n",
      "['17']\n",
      "mar_mo15.txt\n",
      "['15']\n",
      "mar_mo16.txt\n",
      "['16']\n",
      "mar_mo18.txt\n",
      "['18']\n",
      "mar_mo19.txt\n",
      "['19']\n",
      "may17.txt\n",
      "['17']\n",
      "may_mo15.txt\n",
      "['15']\n",
      "may_mo16.txt\n",
      "['16']\n",
      "may_mo18.txt\n",
      "['18']\n",
      "may_mo19.txt\n",
      "['19']\n",
      "nov17.txt\n",
      "['17']\n",
      "nov_mo15.txt\n",
      "['15']\n",
      "nov_mo16.txt\n",
      "['16']\n",
      "nov_mo18.txt\n",
      "['18']\n",
      "oct17.txt\n",
      "['17']\n",
      "oct_mo15.txt\n",
      "['15']\n",
      "oct_mo16.txt\n",
      "['16']\n",
      "oct_mo18.txt\n",
      "['18']\n",
      "sep17.txt\n",
      "['17']\n",
      "sep_mo15.txt\n",
      "['15']\n",
      "sep_mo16.txt\n",
      "['16']\n",
      "sep_mo18.txt\n",
      "['18']\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir():\n",
    "    res = re.findall(r'[0-9]+', file)\n",
    "    if len(str(res))==8:\n",
    "        os.remove(file)\n",
    "        pass\n",
    "    else:\n",
    "        if res[0]=='17':\n",
    "            new_name=res[0]+mes[file[0:3]]+\".txt\"\n",
    "            os.rename(file,new_name)\n",
    "        else:\n",
    "            new_name=res[0]+mes[file[0:6]]+\".txt\"\n",
    "            os.rename(file,new_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que la información en todos los ficheros no es la misma, se van a a tener que modificar alguno de ellos, en concreto los anteriores a Octubre de 2017. Los archivos que se tienen que modificar tienen el incoveniente de que no están separados por comas, cosa fundamental para la limpieza de los datos posterior.\n",
    "\n",
    "En las siguientes lineas se van a añadir comas en aquellas posiciones que el resto de archivos, cuya modificación no es necesaria, la tienen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir():\n",
    "    if file<'1710.txt':\n",
    "        for line in fileinput.FileInput(file,inplace=1):\n",
    "            comas=[2,5,8,10,12,14,16,18,20]\n",
    "            for i,j in enumerate(comas):\n",
    "                line=list(line)\n",
    "                line.insert(i+j,',')\n",
    "            line=line[0:-1]\n",
    "            line=\"\".join(line)\n",
    "            line=re.sub(r\"[^V.,\\-(0-9)]\",\"N\",line)\n",
    "            line=line.replace(\"V\",\",V,\")\n",
    "            line=line.replace(\"N\",\",N,\")          \n",
    "            if line[len(line)-1]==',': line=line[0:(len(line)-1)]\n",
    "            print(line)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
